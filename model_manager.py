import os
import io
import logging
import numpy as np
import tensorflow as tf
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload
from trading_utils import prepare_data

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
MODEL_NAME = "model.keras"
FOLDER_ID = "12GYefwcJwyo4mI4-MwdZzeLZrCAD1I09"

# –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
creds = service_account.Credentials.from_service_account_file(
    "credentials.json", scopes=["https://www.googleapis.com/auth/drive"]
)
drive_service = build("drive", "v3", credentials=creds)


def download_model_from_drive(local_path=MODEL_NAME):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å —Å Google Drive, –µ—Å–ª–∏ –æ–Ω–∞ —Ç–∞–º –µ—Å—Ç—å"""
    logging.info("üîç –ò—â–µ–º –º–æ–¥–µ–ª—å –Ω–∞ Google Drive...")
    response = drive_service.files().list(
        q=f"name='{MODEL_NAME}' and '{FOLDER_ID}' in parents and trashed=false",
        spaces="drive",
        fields="files(id, name)"
    ).execute()
    files = response.get("files", [])

    if not files:
        logging.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ Google Drive.")
        return False

    file_id = files[0]["id"]
    request = drive_service.files().get_media(fileId=file_id)
    fh = io.FileIO(local_path, "wb")
    downloader = MediaIoBaseDownload(fh, request)

    done = False
    while not done:
        _, done = downloader.next_chunk()

    logging.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å Google Drive.")
    return True


def upload_model_to_drive(local_path=MODEL_NAME):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ Google Drive"""
    # –ò—â–µ–º —Ñ–∞–π–ª
    response = drive_service.files().list(
        q=f"name='{MODEL_NAME}' and '{FOLDER_ID}' in parents and trashed=false",
        spaces="drive",
        fields="files(id, name)"
    ).execute()
    files = response.get("files", [])

    media = MediaIoBaseUpload(io.FileIO(local_path, "rb"), mimetype="application/octet-stream")

    if files:
        file_id = files[0]["id"]
        drive_service.files().update(fileId=file_id, media_body=media).execute()
        logging.info("‚úÖ –ú–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ Google Drive.")
    else:
        file_metadata = {"name": MODEL_NAME, "parents": [FOLDER_ID]}
        drive_service.files().create(body=file_metadata, media_body=media, fields="id").execute()
        logging.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ Google Drive.")


def create_model(input_shape):
    """–°–æ–∑–¥–∞—ë—Ç –ø—Ä–æ—Å—Ç—É—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å"""
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=input_shape),
        tf.keras.layers.LSTM(64, return_sequences=True),
        tf.keras.layers.LSTM(32),
        tf.keras.layers.Dense(1, activation="sigmoid")
    ])
    model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
    return model


def train_or_load_model(x_train, y_train, model_path=MODEL_NAME):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ Google Drive –∏–ª–∏ –æ–±—É—á–∞–µ—Ç –Ω–æ–≤—É—é"""
    if not os.path.exists(model_path):
        found = download_model_from_drive(model_path)
        if not found:
            logging.info("üß† –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å.")
            model = create_model(x_train.shape[1:])
        else:
            model = tf.keras.models.load_model(model_path)
    else:
        model = tf.keras.models.load_model(model_path)

    logging.info("üîÅ –ù–∞—á–∏–Ω–∞–µ–º –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.")
    model.fit(x_train, y_train, epochs=3, batch_size=32, verbose=0)
    model.save(model_path)
    upload_model_to_drive(model_path)

    logging.info("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
    return model