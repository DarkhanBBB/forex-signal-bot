import os
import time
import joblib
import numpy as np
import pandas as pd
import yfinance as yf
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from ta.momentum import RSIIndicator
from ta.trend import EMAIndicator, MACD
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload
import io
import requests

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
SCOPES = ['https://www.googleapis.com/auth/drive']
GDRIVE_FOLDER_ID = '12GYefwcJwyo4mI4-MwdZzeLZrCAD1I09'
MODEL_FILENAME = 'forex_model.h5'
CREDENTIALS_FILE = 'credentials.json'
CHECK_INTERVAL_MINUTES = 30
CONFIDENCE_THRESHOLD = 0.8
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")


# === –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è Google Drive ===
def get_drive_service():
    credentials = service_account.Credentials.from_service_account_file(CREDENTIALS_FILE, scopes=SCOPES)
    return build('drive', 'v3', credentials=credentials)
    if os.path.exists(MODEL_FILENAME):
    upload_model(drive_service)
else:
    print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –µ—â—ë –Ω–µ –æ–±—É—á–µ–Ω–∞, —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")

def download_model(service):
    query = f"'{GDRIVE_FOLDER_ID}' in parents and name='{MODEL_FILENAME}' and trashed=false"
    results = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()
    items = results.get('files', [])
    if not items:
        print("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ Google Drive.")
        return False
    file_id = items[0]['id']
    request = service.files().get_media(fileId=file_id)
    fh = io.FileIO(MODEL_FILENAME, 'wb')
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done:
        _, done = downloader.next_chunk()
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å Google Drive.")
    return True

def upload_model(service):
    query = f"'{GDRIVE_FOLDER_ID}' in parents and name='{MODEL_FILENAME}' and trashed=false"
    results = service.files().list(q=query, spaces='drive', fields='files(id, name)').execute()
    items = results.get('files', [])
    media = MediaFileUpload(MODEL_FILENAME, resumable=True)
    if items:
        file_id = items[0]['id']
        service.files().update(fileId=file_id, media_body=media).execute()
    else:
        file_metadata = {'name': MODEL_FILENAME, 'parents': [GDRIVE_FOLDER_ID]}
        service.files().create(body=file_metadata, media_body=media, fields='id').execute()
    print("‚úÖ –ú–æ–¥–µ–ª—å –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ Google Drive.")

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä—ã ===
def analyze_pair(ticker):
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ {ticker}...")
    end_date = datetime.utcnow()
    start_date = end_date - timedelta(days=59)
    data = yf.download(ticker, start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'),
                       interval='15m', progress=False)

    if data.empty or len(data) < 100:
        print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö.")
        return

    close = data['Close']
    data['rsi'] = RSIIndicator(close).rsi()
    data['ema'] = EMAIndicator(close, window=20).ema_indicator()
    data['macd'] = MACD(close).macd_diff()
    data.dropna(inplace=True)

    features = ['Close', 'rsi', 'ema', 'macd']
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data[features].values)

    def create_sequences(data, window=24):
        X, y = [], []
        for i in range(window, len(data)):
            X.append(data[i - window:i])
            y.append(1 if data[i, 0] > data[i - 1, 0] else 0)
        return np.array(X), np.array(y)

    X, y = create_sequences(scaled_data)
    if len(X) == 0:
        print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
        return
    X = X.reshape((X.shape[0], X.shape[1], len(features)))

    # === –û–±—É—á–µ–Ω–∏–µ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===
    if os.path.exists(MODEL_FILENAME):
        model = load_model(MODEL_FILENAME)
        model.fit(X, y, epochs=2, batch_size=32, verbose=0)
    else:
        model = Sequential()
        model.add(LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))
        model.add(Dropout(0.2))
        model.add(LSTM(32))
        model.add(Dense(1, activation='sigmoid'))
        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        model.fit(X, y, epochs=10, batch_size=32, verbose=1)

    model.save(MODEL_FILENAME)

    # === –ü—Ä–æ–≥–Ω–æ–∑ ===
    last_seq = scaled_data[-24:]
    last_seq = last_seq.reshape((1, 24, len(features)))
    prediction = float(model.predict(last_seq, verbose=0)[0][0])
    confidence = round(prediction, 4)

    # === –°–∏–≥–Ω–∞–ª ===
    last_high = data['High'].iloc[-14:]
    last_low = data['Low'].iloc[-14:]
    atr_val = (last_high.max() - last_low.min())
    close_price = float(data['Close'].iloc[-1])
    direction = 'BUY' if prediction > 0.5 else 'SELL'
    tp = close_price + atr_val * 0.5 if direction == 'BUY' else close_price - atr_val * 0.5
    sl = close_price - atr_val * 0.5 if direction == 'BUY' else close_price + atr_val * 0.5

    signal = {
        'timestamp': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
        'pair': ticker,
        'direction': direction,
        'entry_price': round(close_price, 5),
        'take_profit': round(tp, 5),
        'stop_loss': round(sl, 5),
        'confidence': confidence
    }

    if confidence >= CONFIDENCE_THRESHOLD:
        send_telegram_signal(signal)
    else:
        print(f"‚ÑπÔ∏è –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {confidence*100:.2f}% –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞.")

def send_telegram_signal(signal):
    if not TELEGRAM_TOKEN or not CHAT_ID:
        print("‚ùå Telegram –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –Ω–µ –∑–∞–¥–∞–Ω—ã.")
        return

    message = f"""üìà <b>–°–∏–≥–Ω–∞–ª –æ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏</b>
<b>–ü–∞—Ä–∞:</b> {signal['pair']}
<b>–í—Ä–µ–º—è:</b> {signal['timestamp']}
<b>–°–∏–≥–Ω–∞–ª:</b> {signal['direction']}
<b>–¶–µ–Ω–∞ –≤—Ö–æ–¥–∞:</b> {signal['entry_price']}
<b>TP:</b> {signal['take_profit']}
<b>SL:</b> {signal['stop_loss']}
<b>–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:</b> {signal['confidence']*100:.2f}%"""

    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": message,
        "parse_mode": "HTML"
    }

    response = requests.post(url, json=payload)
    if response.status_code == 200:
        print("‚úÖ –°–∏–≥–Ω–∞–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ Telegram.")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –≤ Telegram:", response.text)

# === –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª ===
if __name__ == '__main__':
    drive_service = get_drive_service()
    download_model(drive_service)
    printed_start = False

    while True:
        if not printed_start:
            send_telegram_signal({
                'pair': 'INFO',
                'timestamp': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
                'direction': 'RUNNING',
                'entry_price': 0,
                'take_profit': 0,
                'stop_loss': 0,
                'confidence': 1.0
            })
            printed_start = True

        for sym in ['EURUSD=X', 'XAUUSD=X']:
            try:
                analyze_pair(sym)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {sym}: {e}")

        if model:
    upload_model(drive_service)  # ‚Üê ‚ùå –Ω–µ—Ç –æ—Ç—Å—Ç—É–ø–∞ ‚Äî –±—É–¥–µ—Ç –æ—à–∏–±–∫–∞

        print(f"üïí –ü–∞—É–∑–∞ {CHECK_INTERVAL_MINUTES} –º–∏–Ω—É—Ç...\n")
        time.sleep(CHECK_INTERVAL_MINUTES * 60)
